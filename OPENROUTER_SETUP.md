# ğŸš€ Setup RÃ¡pido con OpenRouter

## Â¿Por quÃ© OpenRouter?

âœ… **Una API key para todos** - GPT-4, Claude, Gemini, Llama, DeepSeek  
âœ… **Modelos GRATIS** - DeepSeek, Llama 3, Mistral  
âœ… **Precios competitivos** - A menudo mÃ¡s barato que directo  
âœ… **Sin lÃ­mites estrictos** - Mejor que OpenAI/Anthropic directo  
âœ… **FacturaciÃ³n transparente** - Ves cuÃ¡nto gastas en tiempo real  

---

## Setup en 3 Pasos

### 1. ObtÃ©n tu API Key (2 minutos)

```bash
# Visita: https://openrouter.ai/
# Click en "Sign In" â†’ "Continue with Google/GitHub"
# Entra a: https://openrouter.ai/keys
# Click "Create Key" â†’ Copia tu sk-or-v1-...
```

### 2. Configura en tu terminal

```bash
export OPENROUTER_API_KEY="sk-or-v1-..."

# Para que sea permanente (aÃ±ade a ~/.bashrc o ~/.config/fish/config.fish):
echo 'export OPENROUTER_API_KEY="sk-or-v1-..."' >> ~/.bashrc
```

### 3. Â¡Ãšsalo!

```bash
# Test rÃ¡pido
python scripts/testing/test_llm_adapters.py \
  --adapter openrouter \
  --model "deepseek/deepseek-coder"

# Pipeline completo
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "deepseek/deepseek-coder"
```

---

## ğŸ†“ Modelos Gratuitos

### Llama 3 8B (RÃ¡pido y GRATIS)
```bash
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "meta-llama/llama-3-8b-instruct"
```

**Por quÃ© es bueno:**
- Muy rÃ¡pido
- GRATIS
- Bueno para exploraciÃ³n rÃ¡pida
- Modelo oficial de Meta

### Llama 3 70B (Alta calidad GRATIS)
```bash
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "meta-llama/llama-3-70b-instruct"
```

**Por quÃ© es bueno:**
- Modelo grande (70B params)
- Muy buena calidad general
- GRATIS
- Buen seguimiento de instrucciones

### Gemini Flash (RÃ¡pido, casi gratis)
```bash
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "google/gemini-flash-1.5"
```

**Por quÃ© es bueno:**
- Extremadamente rÃ¡pido
- Casi gratis ($0.01 por 100 tests)
- Buena calidad
- De Google

---

## ğŸ’° Modelos de Pago (Alta Calidad)

### Claude 3 Sonnet (Equilibrio)
```bash
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "anthropic/claude-3-sonnet"
```

**Costo:** ~$1.50 por 100 tests  
**Por quÃ© vale la pena:**
- Excelente para cÃ³digo complejo
- Muy buen seguimiento de instrucciones
- Menos errores que modelos gratuitos

### GPT-4 Turbo (MÃ¡xima calidad)
```bash
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "openai/gpt-4-turbo"
```

**Costo:** ~$3.00 por 100 tests  
**Por quÃ© vale la pena:**
- Mejor calidad absoluta
- Refinamientos mÃ¡s sofisticados
- Para paper final o producciÃ³n

### Gemini Pro 1.5 (Barato + contexto largo)
```bash
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "google/gemini-pro-1.5"
```

**Costo:** ~$0.12 por 100 tests  
**Por quÃ© vale la pena:**
- Muy barato
- Contexto de 1M tokens
- Bueno para tests grandes

---

## ğŸ“Š ComparaciÃ³n RÃ¡pida

| Modelo | Costo/100 tests | Calidad | Velocidad | Uso Recomendado |
|--------|-----------------|---------|-----------|-----------------|
| **DeepSeek Coder** | **GRATIS** | â­â­â­â­ | âš¡âš¡âš¡âš¡ | **ExploraciÃ³n, desarrollo** |
| **Llama 3 70B** | **GRATIS** | â­â­â­â­ | âš¡âš¡âš¡ | **InvestigaciÃ³n acadÃ©mica** |
| Llama 3 8B | GRATIS | â­â­â­ | âš¡âš¡âš¡âš¡âš¡ | Prototipado rÃ¡pido |
| Gemini Flash | $0.01 | â­â­â­ | âš¡âš¡âš¡âš¡âš¡ | ExploraciÃ³n masiva |
| Gemini Pro 1.5 | $0.12 | â­â­â­â­ | âš¡âš¡âš¡âš¡ | Tests complejos/largos |
| GPT-3.5 | $0.05 | â­â­â­ | âš¡âš¡âš¡âš¡ | Baseline OpenAI |
| Claude Haiku | $0.10 | â­â­â­â­ | âš¡âš¡âš¡âš¡ | RÃ¡pido + calidad |
| **Claude Sonnet** | **$1.50** | **â­â­â­â­â­** | **âš¡âš¡âš¡** | **Paper final** |
| GPT-4 Turbo | $3.00 | â­â­â­â­â­ | âš¡âš¡ | MÃ¡xima calidad |
| Claude Opus | $7.50 | â­â­â­â­â­ | âš¡âš¡ | Casos crÃ­ticos |

---

## ğŸ¯ Workflow Recomendado

### Para Tesis/Paper

```bash
# FASE 1: ExploraciÃ³n (GRATIS)
# Prueba con DeepSeek o Llama 3 para ver si funciona
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "deepseek/deepseek-coder" \
  --limit 10

# FASE 2: Desarrollo (~GRATIS)
# Una vez que funciona, procesa mÃ¡s datos
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "meta-llama/llama-3-70b-instruct" \
  --limit 100

# FASE 3: Paper Final ($1.50)
# Para resultados finales del paper, usa Claude Sonnet
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "anthropic/claude-3-sonnet"
```

**Costo total:** ~$1.50 (solo fase 3)  
**Tiempo ahorrado:** Semanas de desarrollo

---

## ğŸ” Ver Uso y Gastos

OpenRouter te muestra en tiempo real cuÃ¡nto gastas:

1. Visita: https://openrouter.ai/activity
2. Ve tu uso por modelo
3. Exporta para tu paper (transparency)

---

## ğŸ’¡ Tips Pro

### Tip 1: Compara modelos fÃ¡cilmente
```bash
# Prueba 3 modelos diferentes
for model in "deepseek/deepseek-coder" "meta-llama/llama-3-70b-instruct" "anthropic/claude-3-sonnet"
do
  echo "Testing $model..."
  python scripts/testing/test_llm_adapters.py --adapter openrouter --model "$model"
done
```

### Tip 2: Empieza siempre con modelos gratis
```bash
# Primero valida que funcione (GRATIS)
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "deepseek/deepseek-coder" \
  --limit 5

# Luego escala con mejor modelo si es necesario
```

### Tip 3: Usa temperatura baja para consistencia
```bash
# Temperatura 0.1 = mÃ¡s determinista (mejor para tests)
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "anthropic/claude-3-sonnet" \
  --temperature 0.1
```

### Tip 4: Para paper, documenta el modelo exacto
```bash
# En tu paper:
"We used DeepSeek Coder (deepseek/deepseek-coder) via OpenRouter API
for test refinement, with temperature=0.2 and max_tokens=2048"
```

---

## â“ Troubleshooting

### Error: API key not set
```bash
# AsegÃºrate que la variable estÃ© configurada
echo $OPENROUTER_API_KEY

# Si no sale nada:
export OPENROUTER_API_KEY="sk-or-v1-..."
```

### Error: Rate limit
```bash
# OpenRouter tiene lÃ­mites mÃ¡s generosos que otros
# Pero si llegas al lÃ­mite, aÃ±ade un delay:
python scripts/pipeline/phase2_llm_refinement.py \
  --adapter openrouter \
  --model "deepseek/deepseek-coder" \
  --delay 1  # 1 segundo entre requests
```

### Quiero probar sin gastar
```bash
# Usa SOLO modelos gratuitos:
# - deepseek/deepseek-coder
# - meta-llama/llama-3-70b-instruct
# - meta-llama/llama-3-8b-instruct
# - mistralai/mistral-7b-instruct
```

---

## ğŸ“š MÃ¡s Info

- **Todos los modelos:** https://openrouter.ai/models
- **Precios:** https://openrouter.ai/models (click en cada modelo)
- **Docs:** https://openrouter.ai/docs
- **Activity:** https://openrouter.ai/activity (ver tu uso)

---

## ğŸ“ Para tu Tesis

OpenRouter es IDEAL para tesis porque:

1. **Reproducibilidad:** Puedes documentar el modelo exacto usado
2. **Transparencia:** Puedes mostrar costos y uso
3. **Flexibilidad:** Puedes comparar mÃºltiples modelos fÃ¡cilmente
4. **Gratis/Barato:** Modelos gratuitos excelentes + opciones premium

En tu metodologÃ­a puedes escribir:

> "We evaluated our approach using multiple LLMs accessed via OpenRouter API:
> - DeepSeek Coder (free tier) for exploratory development
> - Llama 3 70B (free tier) for baseline results  
> - Claude 3 Sonnet (paid tier, $15/1M tokens) for final results
> 
> Total cost for 500 test refinements: $7.50"

Esto muestra profesionalismo y transparencia ğŸš€
