# ============================================================================
# DEPENDENCIAS LLM PARA FASE 2 (Refinamiento)
# ============================================================================
# 
# Instala solo las que necesites según tu adapter:
#
# OpenAI:     pip install openai
# Anthropic:  pip install anthropic
# HuggingFace: pip install transformers torch accelerate
# Ollama:     pip install requests (ya incluido en requirements.txt)
#
# ============================================================================

# -------------------- OpenAI Adapter --------------------
# Para GPT-4, GPT-3.5, etc.
openai>=1.0.0

# -------------------- Anthropic Adapter --------------------
# Para Claude 3
anthropic>=0.18.0

# -------------------- HuggingFace Adapter --------------------
# Para CodeGemma, CodeLlama, DeepSeek, StarCoder, etc.
transformers>=4.38.0
torch>=2.1.0
accelerate>=0.26.0

# Opcional: Para cuantización (reducir VRAM)
bitsandbytes>=0.41.0  # Solo Linux/WSL

# Opcional: Para optimización
optimum>=1.16.0
flash-attn>=2.5.0  # Solo si tienes Ampere GPU (RTX 30xx+)

# -------------------- Ollama Adapter --------------------
# Ya incluido en requirements.txt base:
# requests>=2.31.0

# ============================================================================
# NOTA: Para un setup mínimo, instala solo lo que uses:
#
# Solo OpenAI:
#   pip install openai
#
# Solo HuggingFace:
#   pip install transformers torch accelerate
#
# Solo Anthropic:
#   pip install anthropic
#
# ============================================================================
